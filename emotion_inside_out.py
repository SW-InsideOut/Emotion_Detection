# -*- coding: utf-8 -*-
"""Emotion_Inside_Out.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/111Wr24sraFce3qWV56UAvL2FWbr3zgZu

#구글 드라이브 마운트
"""

from google.colab import drive
drive.mount('/content/drive')

"""# 기존 데이터셋 파일 3000장으로 8:2 비율/모델있으면 건너뛰기"""

import os
# 원본 데이터 경로
original_dataset_dir = '/content/drive/MyDrive/emotion_detection/train'

# 새 학습 및 검증 데이터 경로
train_dataset_dir = '/content/drive/MyDrive/emotion_detection_balanced/train'
val_dataset_dir = '/content/drive/MyDrive/emotion_detection_balanced/validation'
os.makedirs(train_dataset_dir, exist_ok=True)
os.makedirs(val_dataset_dir, exist_ok=True)

# 감정 클래스 목록에서 'Disgust' 제외
class_labels = ['angry', 'fear', 'happy', 'sad', 'surprise', 'neutral']

from tensorflow.keras.preprocessing.image import ImageDataGenerator
train_generator = ImageDataGenerator(rotation_range=10,  # Degree range for random rotations
                                     zoom_range=0.2,  # Float or [lower, upper]. Range for random zoom. If a float, [lower, upper] = [1-zoom_range, 1+zoom_range]
                                     horizontal_flip=True,  # Randomly flip inputs horizontally
                                     rescale=1/255)  # Rescaling by 1/255 to normalize

#새 트래인 경로로 넣기, 트래인 파일개수 확인
train_dataset = train_generator.flow_from_directory(directory='/content/drive/MyDrive/emotion_detection_balanced/train',
                                                    target_size=(48, 48),  # Tuple of integers (height, width), defaults to (256, 256)
                                                    class_mode='categorical',
                                                    batch_size=16,  # Size of the batches of data (default: 32)
                                                    shuffle=True,  # Whether to shuffle the data (default: True) If set to False, sorts the data in alphanumeric order
                                                    seed=10)

train_dataset.classes #클래스 확인

train_dataset.class_indices #감정별 클래스 확인

#validation 파일 개수 확인
val_generator = ImageDataGenerator(rescale=1/255)

val_dataset = val_generator.flow_from_directory(directory='/content/drive/MyDrive/emotion_detection_balanced/validation',
                                                  target_size=(48, 48),
                                                  class_mode='categorical',
                                                  batch_size=1,
                                                  shuffle=False,
                                                  seed=10)

"""#모델 학습/모델있으면 건너뛰기"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten, BatchNormalization

num_classes = 6
num_detectors = 32
width, height = 48, 48

network = Sequential()

network.add(Conv2D(filters=num_detectors, kernel_size=3, activation='relu', padding='same', input_shape=(width, height, 3)))
network.add(BatchNormalization())
network.add(Conv2D(filters=num_detectors, kernel_size=3, activation='relu', padding='same'))
network.add(BatchNormalization())
network.add(MaxPooling2D(pool_size=(2, 2)))
network.add(Dropout(0.2))

network.add(Conv2D(2*num_detectors, 3, activation='relu', padding='same'))
network.add(BatchNormalization())
network.add(Conv2D(2*num_detectors, 3, activation='relu', padding='same'))
network.add(BatchNormalization())
network.add(MaxPooling2D(pool_size=(2, 2)))
network.add(Dropout(0.2))

network.add(Conv2D(2*2*num_detectors, 3, activation='relu', padding='same'))
network.add(BatchNormalization())
network.add(Conv2D(2*2*num_detectors, 3, activation='relu', padding='same'))
network.add(BatchNormalization())
network.add(MaxPooling2D(pool_size=(2, 2)))
network.add(Dropout(0.2))

network.add(Conv2D(2*2*2*num_detectors, 3, activation='relu', padding='same'))
network.add(BatchNormalization())
network.add(Conv2D(2*2*2*num_detectors, 3, activation='relu', padding='same'))
network.add(BatchNormalization())
network.add(MaxPooling2D(pool_size=(2, 2)))
network.add(Dropout(0.2))

network.add(Flatten())

network.add(Dense(2*2*num_detectors, activation='relu'))
network.add(BatchNormalization())
network.add(Dropout(0.2))

network.add(Dense(2*num_detectors, activation='relu'))
network.add(BatchNormalization())
network.add(Dropout(0.2))

network.add(Dense(num_classes, activation='softmax'))

network.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])

epochs = 30 #40-50으로 늘리는게 좋을듯
history=network.fit(train_dataset, epochs=epochs)

# Keras 형식으로 모델 저장
network.save('/content/drive/MyDrive/emotion_detection_model.keras')

import matplotlib.pyplot as plt

# 손실(Loss) 그래프
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.savefig('/content/drive/MyDrive/loss_graph.png')  # 손실 그래프 저장
plt.show()

# 정확도(Accuracy) 그래프
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.savefig('/content/drive/MyDrive/accuracy_graph.png')  # 정확도 그래프 저장
plt.show()

network.evaluate(test_dataset)

preds = network.predict(test_dataset)
preds

preds = np.argmax(preds, axis=1)
preds

test_dataset.classes

from sklearn.metrics import accuracy_score

accuracy_score(test_dataset.classes, preds)

"""#모델 불러오기 (모델있으면 여기부터)"""

import tensorflow as tf

# 모델 불러오기
model_path = '/content/drive/MyDrive/emotion_detection_model.keras'
network = tf.keras.models.load_model(model_path)

# 모델 요약 정보 출력
network.summary()

"""#이미지 테스트"""

import cv2
from google.colab.patches import cv2_imshow

image = cv2.imread('/content/201912_story_magazine_top_08.jpg') #본인 사진 경로로 변경
cv2_imshow(image)

#얼굴검출,GPU 써야함..
import dlib
face_detector = dlib.cnn_face_detection_model_v1('/content/drive/MyDrive/mmod_human_face_detector.dat')

face_detection = face_detector(image, 1)

#얼굴검출 확인
left, top, right, bottom = face_detection[0].rect.left(), face_detection[0].rect.top(), face_detection[0].rect.right(), face_detection[0].rect.bottom()

roi = image[top:bottom, left:right]

cv2_imshow(roi)

roi.shape

#사진크기 지정
roi = cv2.resize(roi, (48, 48))

roi.shape

import numpy as np
roi = roi / 255
roi = np.expand_dims(roi, axis=0)
roi.shape

# 클래스 이름을 수동으로 정의

class_names = ['angry', 'fear', 'happy', 'sad', 'surprise', 'neutral']
# 확률을 퍼센트로 변환
pred_probability = network.predict(roi)
pred = np.argmax(pred_probability)
confidence_percentages = pred_probability[0] * 100

# 결과 출력
print("감정별 확률:")
for i, class_name in enumerate(class_names):
    print(f"{class_name}: {confidence_percentages[i]:.2f}%")